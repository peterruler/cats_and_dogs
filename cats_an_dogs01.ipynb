{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch  1 of 25000\n",
      "Percentage Done:  0.004 of 25000\n",
      "Loaded batch  2 of 25000\n",
      "Percentage Done:  0.008 of 25000\n",
      "Loaded batch  3 of 25000\n",
      "Percentage Done:  0.012 of 25000\n",
      "Loaded batch  4 of 25000\n",
      "Percentage Done:  0.016 of 25000\n",
      "Loaded batch  5 of 25000\n",
      "Percentage Done:  0.02 of 25000\n",
      "Loaded batch  6 of 25000\n",
      "Percentage Done:  0.024 of 25000\n",
      "Train Epoch: 1 [0/6 (0%)]\tLoss: 0.693651\n",
      "Train Epoch: 1 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 1 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 1 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 1 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 1 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 2 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 2 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 2 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 2 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 2 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 2 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 3 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 3 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 3 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 3 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 3 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 3 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 4 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 4 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 4 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 4 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 4 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 4 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 5 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 5 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 5 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 5 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 5 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 5 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 6 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 6 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 6 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 6 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 6 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 6 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 7 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 7 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 7 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 7 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 7 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 7 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 8 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 8 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 8 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 8 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 8 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 8 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 9 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 9 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 9 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 9 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 9 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 9 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 10 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 10 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 10 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 10 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 10 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 10 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 11 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 11 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 11 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 11 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 11 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 11 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 12 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 12 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 12 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 12 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 12 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 12 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 13 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 13 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 13 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 13 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 13 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 13 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 14 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 14 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 14 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 14 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 14 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 14 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 15 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 15 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 15 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 15 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 15 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 15 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 16 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 16 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 16 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 16 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 16 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 16 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 17 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 17 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 17 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 17 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 17 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 17 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 18 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 18 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 18 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 18 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 18 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 18 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 19 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 19 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 19 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 19 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 19 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 19 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 20 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 20 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 20 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 20 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 20 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 20 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 21 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 21 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 21 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 21 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 21 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 21 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 22 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 22 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 22 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 22 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 22 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 22 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 23 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 23 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 23 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 23 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 23 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 23 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 24 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 24 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 24 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 24 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 24 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 24 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 25 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 25 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 25 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 25 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 25 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 25 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 26 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 26 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 26 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 26 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 26 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 26 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 27 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 27 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 27 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 27 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 27 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 27 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 28 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 28 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 28 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 28 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 28 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 28 [320/6 (83%)]\tLoss: 39.062500\n",
      "Train Epoch: 29 [0/6 (0%)]\tLoss: 46.875000\n",
      "Train Epoch: 29 [64/6 (17%)]\tLoss: 50.000000\n",
      "Train Epoch: 29 [128/6 (33%)]\tLoss: 57.812500\n",
      "Train Epoch: 29 [192/6 (50%)]\tLoss: 42.187500\n",
      "Train Epoch: 29 [256/6 (67%)]\tLoss: 40.625000\n",
      "Train Epoch: 29 [320/6 (83%)]\tLoss: 39.062500\n",
      "is a:  dog\n",
      "tensor([[1]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "# TARGET: [isCat, isDog]\n",
    "train_data_list = []\n",
    "target_list = []\n",
    "train_data = []\n",
    "files = listdir('catdog/train/')\n",
    "for i in range(len(listdir('catdog/train/'))) :\n",
    "    f = random.choice(files)\n",
    "    files.remove(f)\n",
    "    img = Image.open(\"catdog/train/\" + f )\n",
    "    img_tensor = transform(img) #(3,256,256)\n",
    "    train_data_list.append(img_tensor)\n",
    "\n",
    "    isCat = 1 if 'cat' in f else 0\n",
    "    isDog = 1 if 'dog' in f else 0\n",
    "    target = [isCat,isDog]\n",
    "    target_list.append(target)\n",
    "\n",
    "    if len(train_data_list) >= 64:\n",
    "       train_data.append((torch.stack(train_data_list),target_list))\n",
    "       train_data_list = []\n",
    "       target_list = []\n",
    "       print('Loaded batch ', len(train_data), 'of', int(len(listdir('catdog/train/'))))\n",
    "       print('Percentage Done: ', 100*len(train_data) /int(len(listdir('catdog/train/'))), 'of', int(len(listdir('catdog/train/'))))\n",
    "       # print(train_data)\n",
    "       if len(train_data) > 5: # change number of trainings\n",
    "        break\n",
    "\n",
    "class Netz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netz,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 12, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(12, 18, kernel_size=5) #18*28*28 = 14'000 neurons\n",
    "        self.conv4 = nn.Conv2d(18, 24, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(14112, 1000) # 1000 neurons\n",
    "        self.fc2 = nn.Linear(1000, 2) # 2 neurons cat or dog our output\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 14112) # nr of neurons\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x) # neither softmax nor log_softmax dont use here use with binary_cross_entropy\n",
    "    \n",
    "        print(x.size())\n",
    "        exit()\n",
    "\n",
    "model = Netz()\n",
    "model.to(\"mps\") # no gpu on m1 mac, use mps\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "def train(epoch) :\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "    for data, target in train_data:\n",
    "        data = data.to(\"mps\")\n",
    "        target = torch.Tensor(target).to(\"mps\") #m1 without gpu .cuda(), use .to(\"mps\") instead\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        criterion = F.binary_cross_entropy # not nll_loss\n",
    "        loss = criterion(out,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_id * len(data), len(train_data), 100 * batch_id / len(train_data), loss.data))\n",
    "        batch_id = batch_id + 1\n",
    "\n",
    "def test():\n",
    "    model.eval();\n",
    "    files = listdir('catdog/test/')\n",
    "    f = random.choice(files)\n",
    "    img = Image.open('catdog/test/' + f)\n",
    "    img_eval_tensor = transform(img)\n",
    "    img_eval_tensor.unsqueeze_(0)\n",
    "    data = Variable(img_eval_tensor.to(\"mps\"))\n",
    "    out = model(data)\n",
    "    isa = 'dog'\n",
    "    if (int(out.data.max(1,keepdim=True)[1].tolist()[0][0]) == 0) :  # dim 1: 0 is Cat - 1 is dog\n",
    "     isa = 'cat'\n",
    "    \n",
    "    print('is a: ' , isa)\n",
    "    print(out.data.max(1,keepdim=True)[1])\n",
    "\n",
    "    img.show()\n",
    "    x = input('')\n",
    "\n",
    "for epoch in range(1,30):\n",
    "    train(epoch)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeea5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
